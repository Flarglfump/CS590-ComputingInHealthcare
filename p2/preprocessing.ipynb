{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "\n",
    "posInDir = \"data/pos\"\n",
    "negOutDir = \"data/neg\"\n",
    "\n",
    "if (not os.path.isdir(posInDir)):\n",
    "    print(f\"Error: path \\\"{posInDir}\\\" is not a valid directory!\")\n",
    "    exit(1)\n",
    "\n",
    "if (not os.path.exists(negOutDir)):\n",
    "    os.makedirs(negOutDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-01 10:49:06--  https://www.encodeproject.org/files/ENCFF105ZAX/@@download/ENCFF105ZAX.bed.gz\n",
      "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
      "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://encode-public.s3.amazonaws.com/2021/08/31/f1787d77-6d8e-4422-ab2a-93cc84f21f97/ENCFF105ZAX.bed.gz?response-content-disposition=attachment%3B%20filename%3DENCFF105ZAX.bed.gz&AWSAccessKeyId=ASIATGZNGCNX6LBCVFBL&Signature=qqioKxIByze3dbsZSrSBaNyBekY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEB8aCXVzLXdlc3QtMiJHMEUCIQDwgbeFZBr7U6HSY0d9x9hK%2FD3bHRBLzvkec7G%2ByAn4nwIgdRG4jE%2F143Dl9NRey2a8XX7HTz%2F8TSSEaX7le%2FhjPnkqswUISBAAGgwyMjA3NDg3MTQ4NjMiDAUZjgrLlcgYVD72VSqQBZIIlAJ%2B%2F4AeLCzOkELrcmzN2apW2EzWPOAiZaN8khl7brbq5t8JoUmy4QG6Kk%2BKWe89EF80L95Rdn34mn0bphenwI3u94bb0cmow7Y0P9mU3XWzDrys7TvN%2BvXkrl%2BZ7Mu8mTfYYLT6R%2FtfWuCr5wYP0RcNSUBE0hjpLvXvmubgg5uihx%2B%2BQVqw3H8fKoqW6EJUwalZhM4lawGQIKgPxUrh7KOkd4La2xZKypUW29u8zHhGh23%2BTQCTsKXvOBHvPaTvNrQioCzjFe%2FQnmd9zhLZ%2FZsm5XNV9QsB3kzwr8WEwsSkiNz7LtcQ4g034FE9qL2cj632W469TMoIxrbT%2BHk%2BItBW1JjNyCuJwpe2LmA8KCpaePJUQeM6XBINRy94MIEdVT14MvFl%2F6LygcFnu7ayZmBuTZOcWU7XbHqsxbFkx6FR1%2F3UGhuWrafZIpeLMC0dEC71jmbG1%2BorpL5xk1%2BsSm%2F5reFXM9fyCiYW95PxsQ4Eeu9KmCh596WSPDgfJGOsAOGZwjz9c2%2B2REtdkYhK0AMr3hBvkoMz6OwfluoJJa0nCQuZmGsGy6Ft5WcmH4C%2BY2LCB71gqzruPhCfj5iw0Dz4Wcq7m82jybwV0JdpUsAqgQUYWWg0CTIvZ%2B%2B8OKfCxArpg3kuZhbegoNONd3QkIXntQfDvfYywk8SIPl94M1TAtt4QrqTLPq0U%2FoydmeG3yiLGeVKqUxP0Mz3LXj%2FludTrOapMOoY1ddvMhaSXn6j5K28NXNizJPm2yCKK8cBLRGQ0YD%2B3qt%2B92%2BUuLouCBvw%2Bl9hO7ifC8gEUSpngoRPqMpx0%2F4Kyhji%2BaB8L%2FnwdNziZeobyGba5YBZ6X6KeJnn8j0ll7ySUJRwcuF3MPqcq7AGOrEBoYtjLhtpfdBwUczoBGz40GzBT9W5CzbhNgscG9DHExKcHaM9bNWBqugX8zZiJru4IzxGWfRkxJlAl%2Fg5SBdiygt85ljJqGj0DDAU%2Fwuj71jjd%2BDF%2BRMxLcVjoTVtTRpN0Y5RkAmXtgzEWC60Aitq9jZvoX3GdFc4c%2FgWRdMEhq6L%2FeKymZGZsWoAVg3gz34RcA54Mp0faAADIU6xboDWxjxxGdGNDtq9BgYh7tcrJauP&Expires=1712116146 [following]\n",
      "--2024-04-01 10:49:06--  https://encode-public.s3.amazonaws.com/2021/08/31/f1787d77-6d8e-4422-ab2a-93cc84f21f97/ENCFF105ZAX.bed.gz?response-content-disposition=attachment%3B%20filename%3DENCFF105ZAX.bed.gz&AWSAccessKeyId=ASIATGZNGCNX6LBCVFBL&Signature=qqioKxIByze3dbsZSrSBaNyBekY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEB8aCXVzLXdlc3QtMiJHMEUCIQDwgbeFZBr7U6HSY0d9x9hK%2FD3bHRBLzvkec7G%2ByAn4nwIgdRG4jE%2F143Dl9NRey2a8XX7HTz%2F8TSSEaX7le%2FhjPnkqswUISBAAGgwyMjA3NDg3MTQ4NjMiDAUZjgrLlcgYVD72VSqQBZIIlAJ%2B%2F4AeLCzOkELrcmzN2apW2EzWPOAiZaN8khl7brbq5t8JoUmy4QG6Kk%2BKWe89EF80L95Rdn34mn0bphenwI3u94bb0cmow7Y0P9mU3XWzDrys7TvN%2BvXkrl%2BZ7Mu8mTfYYLT6R%2FtfWuCr5wYP0RcNSUBE0hjpLvXvmubgg5uihx%2B%2BQVqw3H8fKoqW6EJUwalZhM4lawGQIKgPxUrh7KOkd4La2xZKypUW29u8zHhGh23%2BTQCTsKXvOBHvPaTvNrQioCzjFe%2FQnmd9zhLZ%2FZsm5XNV9QsB3kzwr8WEwsSkiNz7LtcQ4g034FE9qL2cj632W469TMoIxrbT%2BHk%2BItBW1JjNyCuJwpe2LmA8KCpaePJUQeM6XBINRy94MIEdVT14MvFl%2F6LygcFnu7ayZmBuTZOcWU7XbHqsxbFkx6FR1%2F3UGhuWrafZIpeLMC0dEC71jmbG1%2BorpL5xk1%2BsSm%2F5reFXM9fyCiYW95PxsQ4Eeu9KmCh596WSPDgfJGOsAOGZwjz9c2%2B2REtdkYhK0AMr3hBvkoMz6OwfluoJJa0nCQuZmGsGy6Ft5WcmH4C%2BY2LCB71gqzruPhCfj5iw0Dz4Wcq7m82jybwV0JdpUsAqgQUYWWg0CTIvZ%2B%2B8OKfCxArpg3kuZhbegoNONd3QkIXntQfDvfYywk8SIPl94M1TAtt4QrqTLPq0U%2FoydmeG3yiLGeVKqUxP0Mz3LXj%2FludTrOapMOoY1ddvMhaSXn6j5K28NXNizJPm2yCKK8cBLRGQ0YD%2B3qt%2B92%2BUuLouCBvw%2Bl9hO7ifC8gEUSpngoRPqMpx0%2F4Kyhji%2BaB8L%2FnwdNziZeobyGba5YBZ6X6KeJnn8j0ll7ySUJRwcuF3MPqcq7AGOrEBoYtjLhtpfdBwUczoBGz40GzBT9W5CzbhNgscG9DHExKcHaM9bNWBqugX8zZiJru4IzxGWfRkxJlAl%2Fg5SBdiygt85ljJqGj0DDAU%2Fwuj71jjd%2BDF%2BRMxLcVjoTVtTRpN0Y5RkAmXtgzEWC60Aitq9jZvoX3GdFc4c%2FgWRdMEhq6L%2FeKymZGZsWoAVg3gz34RcA54Mp0faAADIU6xboDWxjxxGdGNDtq9BgYh7tcrJauP&Expires=1712116146\n",
      "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.180.43, 52.92.234.153, 52.92.180.129, ...\n",
      "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.180.43|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2466253 (2.4M) [binary/octet-stream]\n",
      "Saving to: './sample0.bed.gz'\n",
      "\n",
      "./sample0.bed.gz    100%[===================>]   2.35M  4.42MB/s    in 0.5s    \n",
      "\n",
      "2024-04-01 10:49:07 (4.42 MB/s) - './sample0.bed.gz' saved [2466253/2466253]\n",
      "\n",
      "--2024-04-01 10:49:07--  https://www.encodeproject.org/files/ENCFF273DGN/@@download/ENCFF273DGN.bed.gz\n",
      "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
      "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
      "^C\n",
      "gunzip: sample0.bed: unknown suffix -- ignored\n",
      "sample0.bed already exists -- do you wish to overwrite (y or n)? "
     ]
    }
   ],
   "source": [
    "# Fetch bed files\n",
    "! ./fetchData.sh\n",
    "# Extract gzip archive files\n",
    "! ./unpackData.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max positive length: 3744\n",
      "Max negative length: 245889217\n",
      "Cutoff length: 1066\n"
     ]
    }
   ],
   "source": [
    "# Count frequency of sequence lengths to determine ideal cutoff length\n",
    "\n",
    "posLenDict = {}\n",
    "negLenDict = {}\n",
    "\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "\n",
    "  if (filename.endswith(\".bed\") and not \"_trimmed\" in filename):\n",
    "    with open(filepath, \"r\") as infile:\n",
    "      reader = csv.reader(infile, delimiter=\"\\t\")\n",
    "\n",
    "      prevID = \"\"\n",
    "      prevStart = \"\"\n",
    "      prevEnd = \"\"\n",
    "      \n",
    "      for line in reader:\n",
    "        curID = line[0]\n",
    "        curStart = line[1]\n",
    "        curEnd = line[2]\n",
    "\n",
    "        posLen = int(curEnd) - int(curStart) + 1\n",
    "        if posLen in posLenDict:\n",
    "          posLenDict[posLen] += 1\n",
    "        else:\n",
    "          posLenDict[posLen] = 1\n",
    "\n",
    "        if (prevID != \"\" and prevStart != \"\" and prevEnd != \"\" and curID == prevID and curStart != prevEnd and curStart != curEnd):\n",
    "          newID = curID\n",
    "          newStart = int(prevEnd) + 1\n",
    "          newEnd = int(curStart) - 1\n",
    "          if (newEnd > newStart):\n",
    "            negLen = newEnd - newStart + 1\n",
    "            if negLen in negLenDict:\n",
    "              negLenDict[negLen] += 1\n",
    "            else:\n",
    "              negLenDict[negLen] = 1\n",
    "        prevID = curID\n",
    "        prevStart = curStart\n",
    "        prevEnd = curEnd\n",
    "\n",
    "posLenList = sorted(posLenDict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "negLenList = sorted(negLenDict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "posCountTotal = sum(i[1] for i in posLenList)\n",
    "negCountTotal = sum(i[1] for i in negLenList)\n",
    "combinedCountTotal = posCountTotal + negCountTotal\n",
    "\n",
    "combinedCountTarget = math.floor(combinedCountTotal / 2)\n",
    "\n",
    "posIdx = 0\n",
    "negIdx = 0\n",
    "\n",
    "combinedLenList = []\n",
    "while (posIdx < len(posLenList) and negIdx < len(negLenList)):\n",
    "  if (posLenList[posIdx][0] > negLenList[negIdx][0]):\n",
    "    combinedLenList.append(posLenList[posIdx])\n",
    "    posIdx += 1\n",
    "  elif (posLenList[posIdx][0] == negLenList[negIdx][0]):\n",
    "    combinedLenList.append([posLenList[posIdx][0], posLenList[posIdx][1] + negLenList[negIdx][1]])\n",
    "    posIdx += 1\n",
    "    negIdx += 1\n",
    "  else:\n",
    "    combinedLenList.append(negLenList[negIdx])\n",
    "    negIdx += 1\n",
    "while (posIdx < len(posLenList)):\n",
    "  combinedLenList.append(posLenList[posIdx])\n",
    "  posIdx += 1\n",
    "while (negIdx < len(negLenList)):\n",
    "  combinedLenList.append(negLenList[negIdx])\n",
    "  negIdx += 1\n",
    "\n",
    "\n",
    "remaining = combinedCountTotal\n",
    "i = 0\n",
    "while (remaining >= combinedCountTarget):\n",
    "  remaining -= combinedLenList[i][1]\n",
    "  if (remaining < combinedCountTarget):\n",
    "    remaining += combinedLenList[i][1]\n",
    "    break\n",
    "  i += 1\n",
    "\n",
    "cutoffLen = combinedLenList[i][0]\n",
    "\n",
    "maxPosLen = sorted(posLenList, key=operator.itemgetter(0), reverse=True)[0][0]\n",
    "maxNegLen = sorted(negLenList, key=operator.itemgetter(0), reverse=True)[0][0]\n",
    "\n",
    "print(f\"Max positive length: {maxPosLen}\")\n",
    "print(f\"Max negative length: {maxNegLen}\")\n",
    "print(f\"Cutoff length: {cutoffLen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim positive bed files\n",
    "\n",
    "linesWrittenList = []\n",
    "\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "  filename_noext = os.path.splitext(filename)[0]\n",
    "\n",
    "  outfpath = filename_noext + \"_trimmed.bed\"\n",
    "  outfpath = os.path.join(\"data/pos\", outfpath)\n",
    "  \n",
    "  if (filename.endswith(\".bed\") and not \"_trimmed\" in filename):\n",
    "    with open(filepath, \"r\") as infile, open(outfpath, \"w\") as outfile:\n",
    "      reader = csv.reader(infile, delimiter=\"\\t\")\n",
    "      writer = csv.writer(outfile, delimiter=\"\\t\")\n",
    "\n",
    "      prevID = \"\"\n",
    "      prevStart = \"\"\n",
    "      prevEnd = \"\"\n",
    "      \n",
    "      i = 0\n",
    "      j = 0\n",
    "      for line in reader:\n",
    "        curID = line[0]\n",
    "        curStart = line[1]\n",
    "        curEnd = line[2]\n",
    "\n",
    "        newLine = line[:3]\n",
    "        posLen = int(curEnd) - int(curStart) + 1\n",
    "        if (posLen >= cutoffLen):\n",
    "          posLen = min(posLen, cutoffLen)\n",
    "          newEnd = min(int(curEnd), int(curStart) + posLen)\n",
    "          newLine[2] = str(newEnd)\n",
    "          j += 1\n",
    "          writer.writerow(newLine)\n",
    "        i += 1\n",
    "      linesWrittenList.append([os.path.basename(outfpath), j, i])\n",
    "\n",
    "linesWrittenList.sort(key=operator.itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove original untrimmed positive bed files\n",
    "\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "  if (filename.endswith(\".bed\") and not \"_trimmed\" in filename):\n",
    "    os.remove(filepath)\n",
    "\n",
    "# Rename trimmed files\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "\n",
    "  outname = filename[:filename.find(\"_trimmed\")] + \".bed\"\n",
    "  outpath = os.path.join(posInDir, outname)\n",
    "  if (filename.endswith(\"_trimmed.bed\")):\n",
    "    os.rename(filepath, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file \"data/neg/sample11.bed\"...\n",
      "Creating file \"data/neg/sample39.bed\"...\n",
      "Creating file \"data/neg/sample38.bed\"...\n",
      "Creating file \"data/neg/sample10.bed\"...\n",
      "Creating file \"data/neg/sample12.bed\"...\n",
      "Creating file \"data/neg/sample13.bed\"...\n",
      "Creating file \"data/neg/sample17.bed\"...\n",
      "Creating file \"data/neg/sample16.bed\"...\n",
      "Creating file \"data/neg/sample28.bed\"...\n",
      "Creating file \"data/neg/sample14.bed\"...\n",
      "Creating file \"data/neg/sample8.bed\"...\n",
      "Creating file \"data/neg/sample9.bed\"...\n",
      "Creating file \"data/neg/sample15.bed\"...\n",
      "Creating file \"data/neg/sample29.bed\"...\n",
      "Creating file \"data/neg/sample41.bed\"...\n",
      "Creating file \"data/neg/sample40.bed\"...\n",
      "Creating file \"data/neg/sample42.bed\"...\n",
      "Creating file \"data/neg/sample43.bed\"...\n",
      "Creating file \"data/neg/sample30.bed\"...\n",
      "Creating file \"data/neg/sample24.bed\"...\n",
      "Creating file \"data/neg/sample18.bed\"...\n",
      "Creating file \"data/neg/sample4.bed\"...\n",
      "Creating file \"data/neg/sample5.bed\"...\n",
      "Creating file \"data/neg/sample19.bed\"...\n",
      "Creating file \"data/neg/sample25.bed\"...\n",
      "Creating file \"data/neg/sample31.bed\"...\n",
      "Creating file \"data/neg/sample27.bed\"...\n",
      "Creating file \"data/neg/sample33.bed\"...\n",
      "Creating file \"data/neg/sample7.bed\"...\n",
      "Creating file \"data/neg/sample6.bed\"...\n",
      "Creating file \"data/neg/sample32.bed\"...\n",
      "Creating file \"data/neg/sample26.bed\"...\n",
      "Creating file \"data/neg/sample22.bed\"...\n",
      "Creating file \"data/neg/sample36.bed\"...\n",
      "Creating file \"data/neg/sample2.bed\"...\n",
      "Creating file \"data/neg/sample3.bed\"...\n",
      "Creating file \"data/neg/sample37.bed\"...\n",
      "Creating file \"data/neg/sample23.bed\"...\n",
      "Creating file \"data/neg/sample35.bed\"...\n",
      "Creating file \"data/neg/sample21.bed\"...\n",
      "Creating file \"data/neg/sample1.bed\"...\n",
      "Creating file \"data/neg/sample0.bed\"...\n",
      "Creating file \"data/neg/sample20.bed\"...\n",
      "Creating file \"data/neg/sample34.bed\"...\n"
     ]
    }
   ],
   "source": [
    "#  Create Negative Bedfiles (with trimmed sequence lengths)\n",
    "\n",
    "for file in os.listdir(posInDir):\n",
    "    filename = os.fsdecode(file)\n",
    "    filename_noext = os.path.splitext(filename)[0]\n",
    "\n",
    "    filepath = os.path.join(posInDir, filename)\n",
    "    if (filename.endswith(\".bed\")):\n",
    "        outpath = os.path.join(negOutDir, filename)\n",
    "        print(\"Creating file \\\"\", outpath, \"\\\"...\", sep=\"\")\n",
    "        \n",
    "        prevID = \"\"\n",
    "        prevStart = \"\"\n",
    "        prevEnd = \"\"\n",
    "\n",
    "        with open(filepath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "            reader = csv.reader(infile, delimiter=\"\\t\")\n",
    "            writer = csv.writer(outfile, delimiter=\"\\t\")\n",
    "        \n",
    "            for line in reader:\n",
    "                curID = line[0]\n",
    "                curStart = line[1]\n",
    "                curEnd = line[2]\n",
    "\n",
    "                if (prevID != \"\" and prevStart != \"\" and prevEnd != \"\" and curID == prevID and curStart != prevEnd and curStart != curEnd):\n",
    "                    newID = curID\n",
    "                    newStart = int(prevEnd) + 1\n",
    "                    newEnd = int(curStart) - 1\n",
    "                    seqLen = newEnd - newStart + 1\n",
    "                    if (newEnd > newStart and seqLen >= cutoffLen):\n",
    "                        seqLen = min(seqLen, cutoffLen)\n",
    "                        newEnd = min(newEnd, newStart + seqLen)\n",
    "                        writer.writerow([str(newID), str(newStart), str(newEnd)])\n",
    "\n",
    "                prevID = curID\n",
    "                prevStart = curStart\n",
    "                prevEnd = curEnd\n",
    "                continue\n",
    "        continue\n",
    "    else:\n",
    "        print(\"File \\\"\", filepath, \"\\\" is not a valid positive bedfile\", sep='')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy reference genome files from share if needed\n",
    "! ./getRefGenome.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file \"sample0.bed\"\n",
      "Processing file \"sample1.bed\"\n",
      "Processing file \"sample10.bed\"\n",
      "Processing file \"sample11.bed\"\n",
      "Processing file \"sample12.bed\"\n",
      "Processing file \"sample13.bed\"\n",
      "Processing file \"sample14.bed\"\n",
      "Processing file \"sample15.bed\"\n",
      "Processing file \"sample16.bed\"\n",
      "Processing file \"sample17.bed\"\n",
      "Processing file \"sample18.bed\"\n",
      "Processing file \"sample19.bed\"\n",
      "Processing file \"sample2.bed\"\n",
      "Processing file \"sample20.bed\"\n",
      "Processing file \"sample21.bed\"\n",
      "Processing file \"sample22.bed\"\n",
      "Processing file \"sample23.bed\"\n",
      "Processing file \"sample24.bed\"\n",
      "Processing file \"sample25.bed\"\n",
      "Processing file \"sample26.bed\"\n",
      "Processing file \"sample27.bed\"\n",
      "Processing file \"sample28.bed\"\n",
      "Processing file \"sample29.bed\"\n",
      "Processing file \"sample3.bed\"\n",
      "Processing file \"sample30.bed\"\n",
      "Processing file \"sample31.bed\"\n",
      "Processing file \"sample32.bed\"\n",
      "Processing file \"sample33.bed\"\n",
      "Processing file \"sample34.bed\"\n",
      "Processing file \"sample35.bed\"\n",
      "Processing file \"sample36.bed\"\n",
      "Processing file \"sample37.bed\"\n",
      "Processing file \"sample38.bed\"\n",
      "Processing file \"sample39.bed\"\n",
      "Processing file \"sample4.bed\"\n",
      "Processing file \"sample40.bed\"\n",
      "Processing file \"sample41.bed\"\n",
      "Processing file \"sample42.bed\"\n",
      "Processing file \"sample43.bed\"\n",
      "Processing file \"sample5.bed\"\n",
      "Processing file \"sample6.bed\"\n",
      "Processing file \"sample7.bed\"\n",
      "Processing file \"sample8.bed\"\n",
      "Processing file \"sample9.bed\"\n",
      "Processing file \"sample0.bed\"\n",
      "Processing file \"sample1.bed\"\n",
      "Processing file \"sample10.bed\"\n",
      "Processing file \"sample11.bed\"\n",
      "Processing file \"sample12.bed\"\n",
      "Processing file \"sample13.bed\"\n",
      "Processing file \"sample14.bed\"\n",
      "Processing file \"sample15.bed\"\n",
      "Processing file \"sample16.bed\"\n",
      "Processing file \"sample17.bed\"\n",
      "Processing file \"sample18.bed\"\n",
      "Processing file \"sample19.bed\"\n",
      "Processing file \"sample2.bed\"\n",
      "Processing file \"sample20.bed\"\n",
      "Processing file \"sample21.bed\"\n",
      "Processing file \"sample22.bed\"\n",
      "Processing file \"sample23.bed\"\n",
      "Processing file \"sample24.bed\"\n",
      "Processing file \"sample25.bed\"\n",
      "Processing file \"sample26.bed\"\n",
      "Processing file \"sample27.bed\"\n",
      "Processing file \"sample28.bed\"\n",
      "Processing file \"sample29.bed\"\n",
      "Processing file \"sample3.bed\"\n",
      "Processing file \"sample30.bed\"\n",
      "Processing file \"sample31.bed\"\n",
      "Processing file \"sample32.bed\"\n",
      "Processing file \"sample33.bed\"\n",
      "Processing file \"sample34.bed\"\n",
      "Processing file \"sample35.bed\"\n",
      "Processing file \"sample36.bed\"\n",
      "Processing file \"sample37.bed\"\n",
      "Processing file \"sample38.bed\"\n",
      "Processing file \"sample39.bed\"\n",
      "Processing file \"sample4.bed\"\n",
      "Processing file \"sample40.bed\"\n",
      "Processing file \"sample41.bed\"\n",
      "Processing file \"sample42.bed\"\n",
      "Processing file \"sample43.bed\"\n",
      "Processing file \"sample5.bed\"\n",
      "Processing file \"sample6.bed\"\n",
      "Processing file \"sample7.bed\"\n",
      "Processing file \"sample8.bed\"\n",
      "Processing file \"sample9.bed\"\n"
     ]
    }
   ],
   "source": [
    "# Run bedtools on bed files to generate sequence files\n",
    "! ./bedExtract.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra lines in sequence files\n",
    "\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "  filename_noext = os.path.splitext(filename)[0]\n",
    "\n",
    "  outfpath = filename_noext + \"_trimmed.txt\"\n",
    "  outfpath = os.path.join(posInDir, outfpath)\n",
    "  \n",
    "  if (filename.endswith(\".txt\") and not \"_trimmed\" in filename):\n",
    "    with open(filepath, \"r\") as infile, open(outfpath, \"w\") as outfile:\n",
    "\n",
    "      for line in infile:\n",
    "        if (line[0][0] != \">\"):\n",
    "          outfile.write(line.upper())\n",
    "\n",
    "for file in os.listdir(negOutDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(negOutDir, filename)\n",
    "  filename_noext = os.path.splitext(filename)[0]\n",
    "\n",
    "  outfpath = filename_noext + \"_trimmed.txt\"\n",
    "  outfpath = os.path.join(negOutDir, outfpath)\n",
    "  \n",
    "  if (filename.endswith(\".txt\") and not \"_trimmed\" in filename):\n",
    "    with open(filepath, \"r\") as infile, open(outfpath, \"w\") as outfile:\n",
    "      for line in infile:\n",
    "        if (line[0][0] != \">\"):\n",
    "          outfile.write(line.upper())\n",
    "\n",
    "# Remove untrimmed positive sequence files\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "  if (filename.endswith(\".txt\") and not \"_trimmed\" in filename):\n",
    "    os.remove(filepath)\n",
    "\n",
    "# Rename trimmed positive sequence files\n",
    "for file in os.listdir(posInDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(posInDir, filename)\n",
    "\n",
    "  outname = filename[:filename.find(\"_trimmed\")] + \".txt\"\n",
    "  outpath = os.path.join(posInDir, outname)\n",
    "  if (filename.endswith(\"_trimmed.txt\")):\n",
    "    os.rename(filepath, outpath)\n",
    "\n",
    "\n",
    "# Remove untrimmed negative sequence files\n",
    "for file in os.listdir(negOutDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(negOutDir, filename)\n",
    "  if (filename.endswith(\".txt\") and not \"_trimmed\" in filename):\n",
    "    os.remove(filepath)\n",
    "\n",
    "# Rename trimmed negative sequence files\n",
    "for file in os.listdir(negOutDir):\n",
    "  filename = os.fsdecode(file)\n",
    "  filepath = os.path.join(negOutDir, filename)\n",
    "\n",
    "  outname = filename[:filename.find(\"_trimmed\")] + \".txt\"\n",
    "  outpath = os.path.join(negOutDir, outname)\n",
    "  if (filename.endswith(\"_trimmed.txt\")):\n",
    "    os.rename(filepath, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined positive sequence file...\n",
      "Finished creating combined positive sequence file...\n",
      "Creating combined negative sequence file...\n",
      "Finished creating combined negative sequence file...\n"
     ]
    }
   ],
   "source": [
    "# Create combined positive sequence file and combined negative sequence file\n",
    "combinedPosSeqPath = \"data/combined_pos.txt\"\n",
    "combinedNegSeqPath = \"data/combined_neg.txt\"\n",
    "\n",
    "print(\"Creating combined positive sequence file...\")\n",
    "with open(combinedPosSeqPath, \"w\") as combinedPosFile:\n",
    "  for file in os.listdir(posInDir):\n",
    "    filename = os.fsdecode(file)\n",
    "    filepath = os.path.join(posInDir, filename)\n",
    "    with open(filepath, \"r\") as infile:\n",
    "      for line in infile:\n",
    "        combinedPosFile.write(line)\n",
    "print(\"Finished creating combined positive sequence file...\")\n",
    "\n",
    "print(\"Creating combined negative sequence file...\")\n",
    "with open(combinedNegSeqPath, \"w\") as combinedNegFile:\n",
    "  for file in os.listdir(negOutDir):\n",
    "    filename = os.fsdecode(file)\n",
    "    filepath = os.path.join(negOutDir, filename)\n",
    "    with open(filepath, \"r\") as infile:\n",
    "      for line in infile:\n",
    "        combinedNegFile.write(line)\n",
    "print(\"Finished creating combined negative sequence file...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sequences: 1262246\n",
      "Negative sequences: 299368\n",
      "Target sequences: 299368\n"
     ]
    }
   ],
   "source": [
    "combinedCompleteSeqPath = \"data/combined_labeled.tsv\"\n",
    "numPosSeq = 0\n",
    "numNegSeq = 0\n",
    "\n",
    "with open(combinedPosSeqPath, \"r\") as f:\n",
    "    numPosSeq = sum(1 for _ in f)\n",
    "with open(combinedNegSeqPath, \"r\") as f:\n",
    "    numNegSeq = sum(1 for _ in f)\n",
    "\n",
    "numTargetSeq = min(numPosSeq, numNegSeq)\n",
    "print(f\"Positive sequences: {numPosSeq}\")\n",
    "print(f\"Negative sequences: {numNegSeq}\")\n",
    "print(f\"Target sequences: {numTargetSeq}\")\n",
    "\n",
    "posLines = []\n",
    "negLines = []\n",
    "\n",
    "with open(combinedPosSeqPath, \"r\") as posFile, open(combinedNegSeqPath, \"r\") as negFile:\n",
    "    posLines = list(i.strip() for i in posFile)\n",
    "    negLines = list(i.strip() for i in negFile)\n",
    "\n",
    "random.shuffle(posLines)\n",
    "random.shuffle(negLines)\n",
    "\n",
    "with open(combinedCompleteSeqPath, \"w\") as outfile:\n",
    "    writer = csv.writer(outfile, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n",
    "    for i in range(0,numTargetSeq):\n",
    "\n",
    "        writer.writerow(['0', negLines[0]])\n",
    "        writer.writerow(['1', posLines[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
